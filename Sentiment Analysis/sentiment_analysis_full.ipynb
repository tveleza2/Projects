{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk as nl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dataset processing**\n",
    "This dataset was retrieved from: https://www.kaggle.com/datasets/yash612/stockmarket-sentiment-dataset/discussion?sort=hotness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5786</th>\n",
       "      <td>Industry body CII said #discoms are likely to ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>#Gold prices slip below Rs 46,000 as #investor...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5788</th>\n",
       "      <td>Workers at Bajaj Auto have agreed to a 10% wag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>#Sharemarket LIVE: Sensex off day’s high, up 6...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>#Sensex, #Nifty climb off day's highs, still u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5791 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Sentiment\n",
       "0     Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
       "1     user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
       "2     user I'd be afraid to short AMZN - they are lo...          1\n",
       "3                                     MNTA Over 12.00            1\n",
       "4                                      OI  Over 21.37            1\n",
       "...                                                 ...        ...\n",
       "5786  Industry body CII said #discoms are likely to ...         -1\n",
       "5787  #Gold prices slip below Rs 46,000 as #investor...         -1\n",
       "5788  Workers at Bajaj Auto have agreed to a 10% wag...          1\n",
       "5789  #Sharemarket LIVE: Sensex off day’s high, up 6...          1\n",
       "5790  #Sensex, #Nifty climb off day's highs, still u...          1\n",
       "\n",
       "[5791 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'../Sentiment Analysis/stock_data.csv')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Remove unwanted observations**\n",
    "\n",
    "(Duplicates, variables that won't be used, irrelevant values, empty spaces, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of not allowed values are:  0\n",
      "The amount of empty spaces is:\n",
      " Text         0\n",
      "Sentiment    0\n",
      "dtype: int64\n",
      "The amount of duplicated rows is: 0\n"
     ]
    }
   ],
   "source": [
    "print('The amount of not allowed values are: ',len([i for i in df.Sentiment if not ((i==1) or (i==-1))]))\n",
    "print('The amount of empty spaces is:\\n', df.isna().sum())\n",
    "print('The amount of duplicated rows is:', df.duplicated().sum())\n",
    "na_list = df.isna()['Sentiment']\n",
    "df.drop([i for i in range(len(df)) if na_list[i]==True])\n",
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **NLP using NLTK**\n",
    "*Natural language processing using Natural Language Toolkit*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.stem as stm\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "nl.download('popular')\n",
    "nl.download('stopwords')\n",
    "stpw = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tokenization**\n",
    "Use word tokenization to use words as input for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Kickers, on, my, watchlist, XIDE, TIT, SOQ, P...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[user, :, AAP, MOVIE, ., 55, %, return, for, t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[user, I, 'd, be, afraid, to, short, AMZN, -, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[MNTA, Over, 12.00]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[OI, Over, 21.37]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  [Kickers, on, my, watchlist, XIDE, TIT, SOQ, P...          1\n",
       "1  [user, :, AAP, MOVIE, ., 55, %, return, for, t...          1\n",
       "2  [user, I, 'd, be, afraid, to, short, AMZN, -, ...          1\n",
       "3                                [MNTA, Over, 12.00]          1\n",
       "4                                  [OI, Over, 21.37]          1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    text = nl.word_tokenize(text)\n",
    "    return text\n",
    "df['Text'] = df['Text'].apply(tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Lemmatization**\n",
    "Lemmatize the words in the input texts to reduce the model dimmensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:         \n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemm(tokens):\n",
    "    lemmatizer = stm.WordNetLemmatizer()\n",
    "    pos_tag_list = nl.pos_tag(tokens)\n",
    "    lemmatized = [lemmatizer.lemmatize(word,get_wordnet_pos(tag)) for word,tag in pos_tag_list]\n",
    "    return lemmatized\n",
    "\n",
    "df['Text'] = df['Text'].apply(lemm)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Remove unnecessary tokens**\n",
    "stopwords and punctuation signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Kickers, watchlist, XIDE, TIT, SOQ, PNK, CPW,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[user, AAP, MOVIE, 55, return, FEA/GEED, indic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[user, I, 'd, afraid, short, AMZN, look, like,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[MNTA, Over, 12.00]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[OI, Over, 21.37]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5786</th>\n",
       "      <td>[Industry, body, CII, say, discoms, likely, su...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>[Gold, price, slip, Rs, 46,000, investor, book...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5788</th>\n",
       "      <td>[Workers, Bajaj, Auto, agree, 10, wage, cut, p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>[Sharemarket, LIVE, Sensex, day, ’, high, 600,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>[Sensex, Nifty, climb, day, 's, high, still, 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5791 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Sentiment\n",
       "0     [Kickers, watchlist, XIDE, TIT, SOQ, PNK, CPW,...          1\n",
       "1     [user, AAP, MOVIE, 55, return, FEA/GEED, indic...          1\n",
       "2     [user, I, 'd, afraid, short, AMZN, look, like,...          1\n",
       "3                                   [MNTA, Over, 12.00]          1\n",
       "4                                     [OI, Over, 21.37]          1\n",
       "...                                                 ...        ...\n",
       "5786  [Industry, body, CII, say, discoms, likely, su...         -1\n",
       "5787  [Gold, price, slip, Rs, 46,000, investor, book...         -1\n",
       "5788  [Workers, Bajaj, Auto, agree, 10, wage, cut, p...          1\n",
       "5789  [Sharemarket, LIVE, Sensex, day, ’, high, 600,...          1\n",
       "5790  [Sensex, Nifty, climb, day, 's, high, still, 2...          1\n",
       "\n",
       "[5791 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_tokens(tokens,ref_list=None):\n",
    "    if ref_list is None:\n",
    "        ref_list = set()\n",
    "    else:\n",
    "        ref_list = set(ref_list)\n",
    "    filtokens = [token for token in tokens if token not in ref_list]\n",
    "    return filtokens\n",
    "\n",
    "df['Text'] = df['Text'].apply(filter_tokens,ref_list=stpw)\n",
    "df['Text'] = df['Text'].apply(filter_tokens,ref_list=string.punctuation)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mskl\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaive_bayes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GaussianNB\n\u001b[0;32m      5\u001b[0m data_count \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mshape(df)[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import sklearn as skl\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "data_count = np.shape(df)[1]\n",
    "data_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
